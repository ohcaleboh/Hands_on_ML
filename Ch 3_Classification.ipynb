{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook, we'll be working with MNIST, a very common ML dataset of 70K small images of digits handwritten by high schools students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the dataset using scikit-learn\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version = 1)\n",
    "mnist.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at arrays\n",
    "\n",
    "\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 70K images, and each image has 784 features --this is b/c 28 x 28 pixels.\n",
    "Each feature simply represetns one pixel's intensity from 0 (white) to 255 (black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's look at one digit from the dataset:\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap = mpl.cm.binary, interpolation = \"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Looks like a 5, and that is indeed what the label tells us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the label is a string --we prefer int so let's cast y to an int:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is already split inito a training set (first 60K  images) and a test set (last 10K images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a binary classifier\n",
    "Let's try to solve a smaller problem: only try to identify one digit -- the number 5.  We will use a binary classifer capable of distinguishing btw just two classes 5 or not 5. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5) # True for all 5s, False for all other digits. \n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's pick a classifier and train it. A good classifer to start is Stochaistic Gradient Descent (SGD). Advantage: able to handle V large datasets efficiently. Deals / training instances independently --one at a time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state = 42) \n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGDClassifier relies on randomness during training, hence name \"stochaastic\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can detect images of the number 5:\n",
    "\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to assess the performance of a classifier. It is a bit more complex than doing so for a linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caleboh/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95035\n",
      "0.96035\n",
      "0.9604\n"
     ]
    }
   ],
   "source": [
    "# Implementation fo a Cross-Validation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits = 3, random_state = 42)\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_5[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_5[test_index]\n",
    "    \n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred)) # prints 0.9502, 0.96565 and 0. 6495"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The StratifiedKFold class performs stratified sampling (as explained in Chapter 2) to produce folds that contain a representative ratio of each class. At each iteration the code creates a clone of the classifier, trains that clone on the training folds, and makes predictions on the test fold. Then it counts the number of correct predictions and outputs the ratio of correct predictions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95035, 0.96035, 0.9604 ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use the cross_val_score() function to evaluate using K-fold cross-validation:\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv = 3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! The accuracy above 95% & 93 both seem really high! But don't too excited. The dummy clasifier that only classified every image as \"not-5\" class has an accuracy of 90% (see below). Hence, accuracy of classification is not a good test of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y = None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype = bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91125, 0.90855, 0.90915])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv = 3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better alt for evaluation is a confusion matrix. General idea: to count times that instances of class A are wrongly classified as class B (i.e., confuses one with the other) --confusion matrix uses false positive type grid to assess performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53892,   687],\n",
       "       [ 1891,  3530]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now just pass the confusion matrix targer classes (y_train_5) and the predicted classes (y_train_pred):\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_5, y_train_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54579,     0],\n",
       "       [    0,  5421]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_perfect_predictions = y_train_5 # pretend we reached perfection\n",
    "confusion_matrix(y_train_5, y_train_perfect_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision = relevant instance among the retrieved \n",
    "recall = relevant instance retrieved among all relevant instances avaliable. \n",
    "\n",
    "There is a trade-off betwen precision and recall.\n",
    "Let's calculatte precision & Recall --two types of classifier metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370879772350012"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_train_5, y_train_pred) # == 4096/ (4096 + 1522)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6511713705958311"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train_5, y_train_pred) # == 4096 / (4096 + 1325)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dang, so we're only recalling 65% of the 5's\n",
    "\n",
    "It's often helpful to combine the precision and recall metrics into a single metric called F1 score. \n",
    "F1 isthe harmonic mean of precision and recall --harmonic gives more weight to lower values than regular mean.\n",
    "\n",
    "compute the F score below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7325171197343846"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 favors classifiers w/ similar precision and recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKlearn allows you to indirectly set the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = sgd_clf.decision_function([some_digit])\n",
    "y_scores\n",
    "threshold = 0\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "\n",
    "# The SGDClassifier uses the threshold equal to 0, so the previous code returns the same results as predict() method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's raise the threshold\n",
    "\n",
    "threshold = 8000\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "y_some_digit_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This output comfirms that raising the threshold decreases recall\n",
    "# Now let's figure out how you know which threshold to use. \n",
    "\n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv = 3, \n",
    "                            method = \"decision_function\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now w/ these scores, you can compute precision and recalll for all possible thresholds\"\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-1c1caa01c545>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# highlight the threshold, add legend, axis label and grid.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplot_precision_recall_vs_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'precision' is not defined"
     ]
    }
   ],
   "source": [
    "# YOu can plot precision and recall as functions of the threshold value using Matplotlib:\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label = \"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label = \"Recall\")\n",
    "    # highlight the threshold, add legend, axis label and grid.\n",
    "    \n",
    "plot_precision_recall_vs_threshold(precision, recalls, thresholds)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the precision to 90\n",
    "\n",
    "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)] # ~7816\n",
    "\n",
    "# To make predictions on the training set for now\n",
    "\n",
    "y_train_pred_90 = (y_scores >= threshold_90_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the predictions\n",
    "precision_score(y_train_5, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_5, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that even though you can set a high precision, there is a cost incurred by the recall!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The ROC is similar to the concept of precision and recall. However, the ROC plots the true postiive rate (recall/sensitivity) against the false positive rate (specificity). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n",
    "\n",
    "# Now we can plot the FPR by the TPR using matplotlib.\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label = None):\n",
    "    plt.plot(fpr, tpr, linewidth = 2, label = label)\n",
    "    plt.plot([0,1], [0,1], 'k==') # dashed diagnol\n",
    "    # add labels and the grid\n",
    "    \n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the recall, the higher the false positive rate --this is the trade-off. \n",
    "\n",
    "One way to compare classifiers is to measure the area under the curve (AUC). A perâ€ fect classifier will have a ROC AUC equal to 1, whereas a purely random classifier will have a ROC AUC equal to 0.5. Scikit-Learn provides a function to compute the ROC AUC:\n",
    "\n",
    "--note: there should be a straight dotted-line w/ positive slope that represents a random classifier (should turn out a 0.5 area below the curve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calc the AUC -- area under the curve -- \n",
    "# Closer to 1 is a better classifier\n",
    "# Closer to 0.5 is worse classifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_train_5, y_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a rule of thumb, you should prefer the PR (precision/recall) curve whenever the positive class is rare or when you care more about the false positives than the false negatives, and the ROC curve otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to train a random forest classifier and compare the ROC curve to that of SGD classifier. \n",
    "\n",
    "note: randomforestclassifier doesn't have the deicison_fucntion(), instead it has predict_prob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state = 42)\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv = 3,\n",
    "                                   method = \"predict_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But for ROC curves we need scores, not probs, a simple solution is to use positive class's prob as the scores\n",
    "\n",
    "y_scores_forest = y_probas_forest[:, 1] # Score = prob of positive class\n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5, y_scores_forest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the plot and compare the two:\n",
    "\n",
    "plt.plot(fpr, tpr, \"b:\", label = \"SGD\")\n",
    "plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Dotted-line is the SGD and the solid is random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train_5, y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_train_5, y_scores_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification\n",
    "\n",
    "Where binary classifiers only distninguish 2 classes, we will be learning multi-class classifers that have multple categories/classes (e.g. tryin to figure out if image is green, blue, or yellow) --this necessary requieres us to use meta approaches that uses higher order binary classification. \n",
    "### mutliclass classifier: \n",
    "1. random forest\n",
    "2. naive bayes \n",
    "\n",
    "### binary classifier: \n",
    "1. support vector machine\n",
    "2. linear classifier\n",
    "\n",
    "## Strategies for multiclass\n",
    "1. one-vs-all (OvA)\n",
    "Here, you either classify the image as belonging to the specific class (yellow), or not (anything else --blue or green). Hence, you make a class for each of the 3 classes. \n",
    "\n",
    "2. one-vs-one (OvO)\n",
    "You create classes based on binary pairing. (blue vs green, green vs yellow ect).\n",
    "\n",
    "If there are N classes, you need N x (N - 1) / 2 classifiers. \n",
    "\n",
    "When wanting to classify the image, you need to run thet image thru all the 45 classifiers and see which one wins the most duels. The main advantage is each classifer only needs to be trained on the part of the training set for the two classes that it must distinguish. \n",
    "\n",
    "For most Bianry classifiers, OvO is preferred --even though you will inevitably have more datasets to run the algorithms on. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn detects when you try to use binary classification algo for a multi-class task -> it automatically rusn OvA:\n",
    "\n",
    "Let's try this with the sgd classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train) # y_train, not y_train_5\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-31893.03095419, -34419.69069632,  -9530.63950739,\n",
       "          1823.73154031, -22320.14822878,  -1385.80478895,\n",
       "        -26188.91070951, -16147.51323997,  -4604.35491274,\n",
       "        -12050.767298  ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To look under the hood to confirm that OvO was used, \n",
    "# --you can do the following and see that you get 10 scores\n",
    "\n",
    "some_digit_scores = sgd_clf.decision_function([some_digit])\n",
    "some_digit_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(some_digit_scores)\n",
    "sgd_clf.classes_\n",
    "sgd_clf.classes_[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to force sklearn to use OVO or OVA instead of default, you can do the following "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "ovo_clf = OneVsOneClassifier(SGDClassifier(random_state = 42))\n",
    "ovo_clf.fit(X_train, y_train)\n",
    "ovo_clf.predict([some_digit])\n",
    "len(ovo_clf.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'forest_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-7d0d81ed0fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training a random forest classifier is also easy!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mforest_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mforest_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msome_digit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'forest_clf' is not defined"
     ]
    }
   ],
   "source": [
    "# Training a random forest classifier is also easy!\n",
    "\n",
    "forest_clf.fit(X_train, y_train)\n",
    "forest_clf.predict([some_digit])\n",
    "\n",
    "# Note that you don't have to run OvA or OvO since random forest \n",
    "# Can directly classify instances into multiple classes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can call predict_proba() to get a list of prob that the classifer \n",
    "# Assigned to each instance for each class\n",
    "\n",
    "forest_clf.predict_proba([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, you can that the 0.9 at the 5th index indicates that our model predicts with 90% accuracy that the image represents a 5. \n",
    "\n",
    "As usual, we want to cross validate results. Let's use cross_valu_score() to evaluate the accuracy of SGDClassifer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cross_val_score() got an unexpected keyword argument 'scoreing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-8949b6e01e23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgd_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoreing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cross_val_score() got an unexpected keyword argument 'scoreing'"
     ]
    }
   ],
   "source": [
    "cross_val_score(sgd_clf, X_train, y_train, cv = 3, scoreing = \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It get's a 84% on all test folds. If you use a radom classifer, you would get 10% accuracy --so not a bad score. You could still do better tho. e.g. simple scaling of the inputs increases accuracy (ref to ch2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8983, 0.891 , 0.9018])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv = 3, scoring = \"accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis \n",
    "\n",
    "Scaffolding for ML project workflow:\n",
    "\n",
    "1. Exploration of the data\n",
    "2. Trying out multiple models\n",
    "3. Short listing the best models \n",
    "4. Fine-tuning hyperparamters (using GridSearchCV)\n",
    "5. Automating as much as possible\n",
    "6. Now that you have promising model, find ways to improve by analyzing types of errors it makes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coonf_mx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-242c8ab79117>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgd_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconf_mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcoonf_mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'coonf_mx' is not defined"
     ]
    }
   ],
   "source": [
    "# First let's look at a confusion matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv = 3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# that is pretty cryptic, so lets look at a better image representation\n",
    "\n",
    "plt.matshow(conf_mx, cmap = plt.cm.gray)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusion matrix looks good since most images on are on the main diagnol which means that they were classified correctly. 5s lookk slightly darker than the other digits --means that either there were fewer images of 5s in dataset or the classifer did not perform as well on the 5s as on other digits. However, you can verify whether both were the case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to divide each value in the confusion matrix by number \n",
    "# of images in the corresponding class, so you can compare error rates \n",
    "# instead of absolute value of the number of errors. \n",
    "\n",
    "row_sums = conf_mx.sum(axis = 1, keepdims = True)\n",
    "norm_conf_mx = conf_mx / row_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Okay now let's fill the diagnols w/ zeros (0s mean true) to keep only errors\n",
    "\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now we can clearly see the errors the model makes. Rows represent actual classes. Columns represented the numbers that were predicted by the model. \n",
    "\n",
    "Hence, the white being errors, you see that 8 are the most poorly predicted by our model. You also see that 5s/3s are mixed up both ways since there are white spots in the columns and the rows. \n",
    "\n",
    "Analyzing individual errors could be a good way to gain insights on what your classifier is doing wrong and why it is failing --but the trade-off is that this is time-consuming. Let's do it anyways.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matplotlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-51f47305a8b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m221\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplot_digits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_aa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_per_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m222\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplot_digits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_per_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m223\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplot_digits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_per_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-0d6f40a7efd1>\u001b[0m in \u001b[0;36mplot_digits\u001b[0;34m(instances, images_per_row, **options)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mrow_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matplotlib' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot exampels of 3s and 5s\n",
    "\n",
    "cl_a, cl_b = 3, 5\n",
    "X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\n",
    "X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\n",
    "X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\n",
    "X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.subplot(221); plot_digits(X_aa[:25], images_per_row = 5)\n",
    "plt.subplot(222); plot_digits(X_ab[:25], images_per_row = 5)\n",
    "plt.subplot(223); plot_digits(X_ba[:25], images_per_row = 5)\n",
    "plt.subplot(224); plot_digits(X_bb[:25], images_per_row = 5)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bottom left and top right blocks are digits that the classifier gets wrong. You learn that 3/5 errors is a consequence of the small line that joins the top line to the bottom arc. Hence the classifier is sensitive to image shifting and rotating. So one way to reduce error is to preprocess the timages to ensure they are well centered and not too rotated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-labeled Classification\n",
    "\n",
    "What if you want a classification systemt hta outputs multiple binary tags (e.g. you want algo to identify all the people within a picture --either they are the person, or not)\n",
    "\n",
    "In the code below, we create an array containing two target labels for each digit image: first indicates whether or not digit is larger than (7,8, or 9) and the second tells whetehr or not it is odd. \n",
    "\n",
    "Next line creates a K-neighbors-classifier instance, and we train it using the mutlple targets array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "y_train_large = (y_train >= 7)\n",
    "y_train_odd = (y_train % 2 == 1)\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can make a predicition and notice it outputs 2 labels:\n",
    "\n",
    "knn_clf.predict([some_digit])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that is true, the 5 is indeed not large(False) and odd(True)!\n",
    "\n",
    "There are ways to evaluate the performance (see book for more details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multioupt classification\n",
    "\n",
    "This is the last classification task we look at. Put simly, it is a geranlization of the previous multi-class calssification --hence each label can have multiple values. \n",
    "\n",
    "e.g. Here we make a function that takes in a noisy digit image, and outputs a clean digit number. \n",
    "\n",
    "The classifier's output is multilabeled (one label per pixel) and each label has multple values (pixel rangin from 0 to 255). This is therefore a multioutput classification system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets, taking MNIST imgaes + \n",
    "# --adding noise to their pixel intensities using randint() function. \n",
    "\n",
    "noise = np.random.randint(0, 100, (len(X_train), 784))\n",
    "X_train_mod = X_train + noise \n",
    "noise = np.random.randint(0, 100, (len(X_test), 784))\n",
    "X_test_mod = X_test + noise\n",
    "y_train_mod = X_train\n",
    "y_train_mod = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [60000, 10000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-49b4d50e7c32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Now, let's kuse the classifer to make the image clean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mknn_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_mod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclean_digit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test_mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msome_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_digit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_digit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \"\"\"\n\u001b[1;32m   1130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n\u001b[0m\u001b[1;32m   1132\u001b[0m                                        multi_output=True)\n\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    257\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [60000, 10000]"
     ]
    }
   ],
   "source": [
    "# Now, let's kuse the classifer to make the image clean\n",
    "\n",
    "knn_clf.fit(X_train_mod, y_train_mod)\n",
    "clean_digit = knn_clf.predict([X_test_mod[some_index]])\n",
    "plot_digit(clean_digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exersizes \n",
    "see page 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
